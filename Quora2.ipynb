{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55ab63f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import fuzzywuzzy\n",
    "import distance\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "from distance import lcsubstrings\n",
    "from nltk.stem import PorterStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Load the cleaned dataset\n",
    "df = pd.read_csv(\"quora_cleaned_train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ed00125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>freq_qid1</th>\n",
       "      <th>freq_qid2</th>\n",
       "      <th>q1len</th>\n",
       "      <th>q2len</th>\n",
       "      <th>q1_n_words</th>\n",
       "      <th>q2_n_words</th>\n",
       "      <th>word_Common</th>\n",
       "      <th>word_Total</th>\n",
       "      <th>word_share</th>\n",
       "      <th>freq_q1+q2</th>\n",
       "      <th>freq_q1-q2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>57</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>88</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>59</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  freq_qid1  \\\n",
       "0  What is the step by step guide to invest in sh...             0          1   \n",
       "1  What would happen if the Indian government sto...             0          4   \n",
       "2  How can Internet speed be increased by hacking...             0          1   \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0          1   \n",
       "4            Which fish would survive in salt water?             0          3   \n",
       "\n",
       "   freq_qid2  q1len  q2len  q1_n_words  q2_n_words  word_Common  word_Total  \\\n",
       "0          1     66     57          14          12           10          13   \n",
       "1          1     51     88           8          13            4          16   \n",
       "2          1     73     59          14          10            4          20   \n",
       "3          1     50     65          11           9            0          19   \n",
       "4          1     76     39          13           7            2          18   \n",
       "\n",
       "   word_share  freq_q1+q2  freq_q1-q2  \n",
       "0    0.769231           2           0  \n",
       "1    0.250000           5           3  \n",
       "2    0.200000           2           0  \n",
       "3    0.000000           2           0  \n",
       "4    0.111111           4           2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()  # Display the first few rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "926eb263",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:143: SyntaxWarning: invalid escape sequence '\\W'\n",
      "<>:143: SyntaxWarning: invalid escape sequence '\\W'\n",
      "C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_20824\\1952768753.py:143: SyntaxWarning: invalid escape sequence '\\W'\n",
      "  pattern = re.compile('\\W')\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "SAFE_DIV = 0.0001\n",
    "\n",
    "STOP_WORDS = stopwords.words(\"english\")\n",
    "\n",
    "# Extended contractions dictionary\n",
    "contractions = {\n",
    "    \"ain't\": \"am not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"can not\",\n",
    "    \"can't've\": \"can not have\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"couldn't've\": \"could not have\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hadn't've\": \"had not have\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'd've\": \"he would have\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he'll've\": \"he will have\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'd'y\": \"how do you\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"i'd\": \"i would\",\n",
    "    \"i'd've\": \"i would have\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"i'll've\": \"i will have\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"it'd've\": \"it would have\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it'll've\": \"it will have\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mightn't've\": \"might not have\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"mustn't've\": \"must not have\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"needn't've\": \"need not have\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"oughtn't've\": \"ought not have\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"sha'n't\": \"shall not\",\n",
    "    \"shan't've\": \"shall not have\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'd've\": \"she would have\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she'll've\": \"she will have\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"shouldn't've\": \"should not have\",\n",
    "    \"so've\": \"so have\",\n",
    "    \"so's\": \"so as\",\n",
    "    \"that'd\": \"that would\",\n",
    "    \"that'd've\": \"that would have\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what'll\": \"what will\",\n",
    "    \"what'll've\": \"what will have\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"when've\": \"when have\",\n",
    "    \"where'd\": \"where did\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"where've\": \"where have\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who'll've\": \"who will have\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"who've\": \"who have\",\n",
    "    \"why's\": \"why is\",\n",
    "    \"why've\": \"why have\",\n",
    "    \"will've\": \"will have\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"won't've\": \"will not have\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"wouldn't've\": \"would not have\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"y'all'd\": \"you all would\",\n",
    "    \"y'all'd've\": \"you all would have\",\n",
    "    \"y'all're\": \"you all are\",\n",
    "    \"y'all've\": \"you all have\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'd've\": \"you would have\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you'll've\": \"you will have\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "def preprocess(x):\n",
    "    x = str(x).lower()\n",
    "\n",
    "    # Existing replacements (unchanged)\n",
    "    x = x.replace(\",000,000\", \"m\").replace(\",000\", \"k\").replace(\"′\", \"'\").replace(\"’\", \"'\")\\\n",
    "         .replace(\"won't\", \"will not\").replace(\"cannot\", \"can not\").replace(\"can't\", \"can not\")\\\n",
    "         .replace(\"n't\", \" not\").replace(\"what's\", \"what is\").replace(\"it's\", \"it is\")\\\n",
    "         .replace(\"'ve\", \" have\").replace(\"i'm\", \"i am\").replace(\"'re\", \" are\")\\\n",
    "         .replace(\"he's\", \"he is\").replace(\"she's\", \"she is\").replace(\"'s\", \" own\")\\\n",
    "         .replace(\"%\", \" percent \").replace(\"₹\", \" rupee \").replace(\"$\", \" dollar \")\\\n",
    "         .replace(\"€\", \" euro \").replace(\"'ll\", \" will\")\n",
    "\n",
    "    # Additional replacements\n",
    "    x = x.replace('@', ' at ')\n",
    "    x = x.replace('[math]', '')\n",
    "\n",
    "    x = x.replace(',000,000,000 ', 'b ')\n",
    "    x = x.replace(',000,000 ', 'm ')\n",
    "    x = x.replace(',000 ', 'k ')\n",
    "    x = re.sub(r'([0-9]+)000000000', r'\\1b', x)\n",
    "    x = re.sub(r'([0-9]+)000000', r'\\1m', x)\n",
    "    x = re.sub(r'([0-9]+)000', r'\\1k', x)\n",
    "\n",
    "    # Expand contractions from dictionary\n",
    "    x_tokens = []\n",
    "    for word in x.split():\n",
    "        if word in contractions:\n",
    "            word = contractions[word]\n",
    "        x_tokens.append(word)\n",
    "    x = ' '.join(x_tokens)\n",
    "\n",
    "    # Continue with original code flow\n",
    "    porter = PorterStemmer()\n",
    "    pattern = re.compile('\\W')\n",
    "\n",
    "    if isinstance(x, str):\n",
    "        x = re.sub(pattern, ' ', x)\n",
    "\n",
    "    if isinstance(x, str):\n",
    "        x = porter.stem(x)\n",
    "        example1 = BeautifulSoup(x, features=\"html.parser\")\n",
    "        x = example1.get_text()\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a025f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating basic features...\n",
      "Calculating token features...\n",
      "Calculating fuzzy features...\n",
      "Calculating longest substring ratio...\n",
      "All features successfully added to the dataframe!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>freq_qid1</th>\n",
       "      <th>freq_qid2</th>\n",
       "      <th>q1len</th>\n",
       "      <th>q2len</th>\n",
       "      <th>...</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>token_set_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>100</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>100</td>\n",
       "      <td>0.982759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>what is the story of kohinoor  koh i noor  dia...</td>\n",
       "      <td>what would happen if the indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>86</td>\n",
       "      <td>63</td>\n",
       "      <td>66</td>\n",
       "      <td>75</td>\n",
       "      <td>0.596154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>how can internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>why am i mentally very lonely  how can i solve...</td>\n",
       "      <td>find the remainder when 23  24   math  is divi...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "      <td>0.039216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>which one dissolve in water quikly sugar  salt...</td>\n",
       "      <td>which fish would survive in salt water</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>0.307690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>67</td>\n",
       "      <td>47</td>\n",
       "      <td>46</td>\n",
       "      <td>56</td>\n",
       "      <td>0.175000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  what is the step by step guide to invest in sh...   \n",
       "1   1     3     4  what is the story of kohinoor  koh i noor  dia...   \n",
       "2   2     5     6  how can i increase the speed of my internet co...   \n",
       "3   3     7     8  why am i mentally very lonely  how can i solve...   \n",
       "4   4     9    10  which one dissolve in water quikly sugar  salt...   \n",
       "\n",
       "                                           question2  is_duplicate  freq_qid1  \\\n",
       "0  what is the step by step guide to invest in sh...             0          1   \n",
       "1  what would happen if the indian government sto...             0          4   \n",
       "2  how can internet speed be increased by hacking...             0          1   \n",
       "3  find the remainder when 23  24   math  is divi...             0          1   \n",
       "4            which fish would survive in salt water              0          3   \n",
       "\n",
       "   freq_qid2  q1len  q2len  ...   ctc_max  last_word_eq  first_word_eq  \\\n",
       "0          1     66     57  ...  0.785709           0.0            1.0   \n",
       "1          1     51     88  ...  0.466664           0.0            1.0   \n",
       "2          1     73     59  ...  0.285712           0.0            1.0   \n",
       "3          1     50     59  ...  0.000000           0.0            0.0   \n",
       "4          1     76     39  ...  0.307690           0.0            1.0   \n",
       "\n",
       "   abs_len_diff  mean_len  token_set_ratio  token_sort_ratio  fuzz_ratio  \\\n",
       "0           2.0      13.0              100                93          93   \n",
       "1           5.0      12.5               86                63          66   \n",
       "2           4.0      12.0               66                66          54   \n",
       "3           1.0      11.5               36                37          36   \n",
       "4           6.0      10.0               67                47          46   \n",
       "\n",
       "   fuzz_partial_ratio  longest_substr_ratio  \n",
       "0                 100              0.982759  \n",
       "1                  75              0.596154  \n",
       "2                  54              0.166667  \n",
       "3                  40              0.039216  \n",
       "4                  56              0.175000  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw questions → preprocessing → all features → final dataset,\n",
    "\n",
    "\n",
    "\n",
    "def get_basic_features(q1, q2):\n",
    "    \"\"\"\n",
    "    Calculates basic features on preprocessed questions\n",
    "    \"\"\"\n",
    "    q1len = len(q1)\n",
    "    q2len = len(q2)\n",
    "    \n",
    "    q1_n_words = len(q1.split())\n",
    "    q2_n_words = len(q2.split())\n",
    "    \n",
    "    q1_words_set = set(q1.split())\n",
    "    q2_words_set = set(q2.split())\n",
    "    word_Common = len(q1_words_set & q2_words_set)\n",
    "    word_Total = len(q1_words_set) + len(q2_words_set)\n",
    "    word_share = word_Common / (word_Total + SAFE_DIV)\n",
    "    \n",
    "    freq_q1_plus_q2 = q1len + q2len\n",
    "    freq_q1_minus_q2 = abs(q1len - q2len)\n",
    "    \n",
    "    return [q1len, q2len, q1_n_words, q2_n_words, word_Common, word_Total, word_share, freq_q1_plus_q2, freq_q1_minus_q2]\n",
    "\n",
    "# 2) Token features function (already exists)\n",
    "def get_token_features(q1, q2):\n",
    "    token_features = [0.0]*10\n",
    "    q1_tokens = q1.split()\n",
    "    q2_tokens = q2.split()\n",
    "    \n",
    "    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n",
    "        return token_features\n",
    "\n",
    "    q1_words = set([word for word in q1_tokens if word not in STOP_WORDS])\n",
    "    q2_words = set([word for word in q2_tokens if word not in STOP_WORDS])\n",
    "    q1_stops = set([word for word in q1_tokens if word in STOP_WORDS])\n",
    "    q2_stops = set([word for word in q2_tokens if word in STOP_WORDS])\n",
    "\n",
    "    common_word_count = len(q1_words.intersection(q2_words))\n",
    "    common_stop_count = len(q1_stops.intersection(q2_stops))\n",
    "    common_token_count = len(set(q1_tokens).intersection(set(q2_tokens)))\n",
    "\n",
    "    token_features[0] = common_word_count / (min(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
    "    token_features[1] = common_word_count / (max(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
    "    token_features[2] = common_stop_count / (min(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
    "    token_features[3] = common_stop_count / (max(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
    "    token_features[4] = common_token_count / (min(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
    "    token_features[5] = common_token_count / (max(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
    "    token_features[6] = int(q1_tokens[-1] == q2_tokens[-1])\n",
    "    token_features[7] = int(q1_tokens[0] == q2_tokens[0])\n",
    "    token_features[8] = abs(len(q1_tokens) - len(q2_tokens))\n",
    "    token_features[9] = (len(q1_tokens) + len(q2_tokens))/2\n",
    "    \n",
    "    return token_features\n",
    "\n",
    "# 3) Longest common substring ratio\n",
    "def get_longest_substr_ratio(a, b):\n",
    "    strs = list(distance.lcsubstrings(a, b))\n",
    "    if len(strs) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(strs[0]) / (min(len(a), len(b)) + 1)\n",
    "\n",
    "# 4) Main feature extraction function\n",
    "def extract_all_features_quora(df):\n",
    "    \"\"\"\n",
    "    Preprocesses the questions and calculates all basic + advanced features\n",
    "    Updates the dataframe df in-place\n",
    "    \"\"\"\n",
    "    # Step 1: Preprocess questions\n",
    "    df[\"question1\"] = df[\"question1\"].fillna(\"\").apply(preprocess)\n",
    "    df[\"question2\"] = df[\"question2\"].fillna(\"\").apply(preprocess)\n",
    "\n",
    "    print(\"Calculating basic features...\")\n",
    "    basic_features = df.apply(lambda x: get_basic_features(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    df[\"q1len\"] = list(map(lambda x: x[0], basic_features))\n",
    "    df[\"q2len\"] = list(map(lambda x: x[1], basic_features))\n",
    "    df[\"q1_n_words\"] = list(map(lambda x: x[2], basic_features))\n",
    "    df[\"q2_n_words\"] = list(map(lambda x: x[3], basic_features))\n",
    "    df[\"word_Common\"] = list(map(lambda x: x[4], basic_features))\n",
    "    df[\"word_Total\"] = list(map(lambda x: x[5], basic_features))\n",
    "    df[\"word_share\"] = list(map(lambda x: x[6], basic_features))\n",
    "    df[\"freq_q1+q2\"] = list(map(lambda x: x[7], basic_features))\n",
    "    df[\"freq_q1-q2\"] = list(map(lambda x: x[8], basic_features))\n",
    "    \n",
    "    # Step 2: Token features\n",
    "    print(\"Calculating token features...\")\n",
    "    token_features = df.apply(lambda x: get_token_features(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    df[\"cwc_min\"]       = list(map(lambda x: x[0], token_features))\n",
    "    df[\"cwc_max\"]       = list(map(lambda x: x[1], token_features))\n",
    "    df[\"csc_min\"]       = list(map(lambda x: x[2], token_features))\n",
    "    df[\"csc_max\"]       = list(map(lambda x: x[3], token_features))\n",
    "    df[\"ctc_min\"]       = list(map(lambda x: x[4], token_features))\n",
    "    df[\"ctc_max\"]       = list(map(lambda x: x[5], token_features))\n",
    "    df[\"last_word_eq\"]  = list(map(lambda x: x[6], token_features))\n",
    "    df[\"first_word_eq\"] = list(map(lambda x: x[7], token_features))\n",
    "    df[\"abs_len_diff\"]  = list(map(lambda x: x[8], token_features))\n",
    "    df[\"mean_len\"]      = list(map(lambda x: x[9], token_features))\n",
    "    \n",
    "    # Step 3: Fuzzy features\n",
    "    print(\"Calculating fuzzy features...\")\n",
    "    df[\"token_set_ratio\"]       = df.apply(lambda x: fuzz.token_set_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    df[\"token_sort_ratio\"]      = df.apply(lambda x: fuzz.token_sort_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    df[\"fuzz_ratio\"]            = df.apply(lambda x: fuzz.QRatio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    df[\"fuzz_partial_ratio\"]    = df.apply(lambda x: fuzz.partial_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    \n",
    "    # Step 4: Longest substring ratio\n",
    "    print(\"Calculating longest substring ratio...\")\n",
    "    df[\"longest_substr_ratio\"]  = df.apply(lambda x: get_longest_substr_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    \n",
    "    print(\"All features successfully added to the dataframe!\")\n",
    "    return df\n",
    "\n",
    "quora_cleaned_train = extract_all_features_quora(df)\n",
    "# Apply to your dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d200f02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>freq_qid1</th>\n",
       "      <th>freq_qid2</th>\n",
       "      <th>q1len</th>\n",
       "      <th>q2len</th>\n",
       "      <th>q1_n_words</th>\n",
       "      <th>q2_n_words</th>\n",
       "      <th>word_Common</th>\n",
       "      <th>word_Total</th>\n",
       "      <th>word_share</th>\n",
       "      <th>freq_q1+q2</th>\n",
       "      <th>freq_q1-q2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>57</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>88</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>59</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  freq_qid1  \\\n",
       "0  What is the step by step guide to invest in sh...             0          1   \n",
       "1  What would happen if the Indian government sto...             0          4   \n",
       "2  How can Internet speed be increased by hacking...             0          1   \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0          1   \n",
       "4            Which fish would survive in salt water?             0          3   \n",
       "\n",
       "   freq_qid2  q1len  q2len  q1_n_words  q2_n_words  word_Common  word_Total  \\\n",
       "0          1     66     57          14          12           10          13   \n",
       "1          1     51     88           8          13            4          16   \n",
       "2          1     73     59          14          10            4          20   \n",
       "3          1     50     65          11           9            0          19   \n",
       "4          1     76     39          13           7            2          18   \n",
       "\n",
       "   word_share  freq_q1+q2  freq_q1-q2  \n",
       "0    0.769231           2           0  \n",
       "1    0.250000           5           3  \n",
       "2    0.200000           2           0  \n",
       "3    0.000000           2           0  \n",
       "4    0.111111           4           2  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0323a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset saved as 'quora_cleaned_train_final.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save the updated DataFrame to CSV\n",
    "quora_cleaned_train.to_csv(\"quora_cleaned_train_final.csv\", index=False)\n",
    "\n",
    "print(\"Final dataset saved as 'quora_cleaned_train_final.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91a40e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b269a19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2963c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db5a8d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3909e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2394c25a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368b71ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd099c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343cceff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d30772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf682b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47011cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23af96e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafdf6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ccc87b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6fb30e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1bcf45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dd1634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ec55cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69175d55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412a2805",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
